Configuration file explanation
===========================

- Each model corresponds to its own configuration file, which is saved under `configs`
- Model

    ```python
    '''
    A complete model consists of backbone, neck, head, and head.loss;

    type corresponds to the corresponding structure, followed by the parameters required to build the structure, and each configuration file has been set;

    The `type` in the configuration file is not a parameter during construction, but the class name.

    What needs to be modified: num_classes is modified to the corresponding number. For example, if the flower data set is five categories, then `num_classes=5`

    Note that if the number of categories is less than 5, the default top5 accuracy is 100%.
    '''
    model_cfg = dict(
        backbone=dict(
            type='ResNet',          # Backbone network type
            depth=50,               # Backbone network depth, ResNet generally has 18, 34, 50, 101, 152 to choose from
            num_stages=4,           # The number of backbone network states (stages). The feature maps generated by these states serve as input to the subsequent head.
            out_indices=(3, ),      # Output feature map output index. The further away from the input image, the larger the index
            frozen_stages=-1,       # During network fine-tuning, freeze the stages of the network (the backpropagation algorithm is not executed during training). If num_stages=4, the backbone contains stem and 4 stages. When frozen_stages is -1, the network is not frozen; when it is 0, the stem is frozen; when it is 1, stem and stage1 are frozen; when it is 4, the entire backbone is frozen
            style='pytorch'),       # The style of the backbone network, 'pytorch' means that the layer with a stride of 2 is a 3x3 convolution, and 'caffe' means that the layer with a stride of 2 is a 1x1 convolution.
        neck=dict(type='GlobalAveragePooling'),    # Neck network type
        head=dict(
            type='LinearClsHead',     # Linear classification header,
            num_classes=1000,         # Output the number of categories, which is consistent with the number of categories in the data set
            in_channels=2048,         #The number of input channels, which is consistent with the output channel of the neck
            loss=dict(type='CrossEntropyLoss', loss_weight=1.0), #Loss function configuration information
            topk=(1, 5),              # Evaluation index, Top-k accuracy, here are top1 and top5 accuracy
        ))
    ```

- Datasets

    ```python
    '''
    This part corresponds to the Datasets when building training/testing, and all methods are under core/datasets;

    size=224: is the image size fed to the network after final processing;

    LoadImageFromFile: load images;

    Normalize: corresponding to normalization, uses the mean and variance of the ImageNet data set by default. If you have the parameters of your own data set, you can choose to overwrite it;

    ImageToTensor: converts images from array to tensor format in Pytorch;

    ToTensor: convert the label file to tensor format in Pytorch;

    Collect: collect pictures, tags, paths and other information.

    '''
    img_norm_cfg = dict(
        mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)

    policies = [
        [
            dict(type='Posterize', bits=4, prob=0.4),
            dict(type='Rotate', angle=30., prob=0.6)
        ],
        [
            dict(type='Solarize', thr=256 / 9 * 4, prob=0.6),
            dict(type='AutoContrast', prob=0.6)
        ],
        [dict(type='Equalize', prob=0.8),
        dict(type='Equalize', prob=0.6)],
        [
            dict(type='Posterize', bits=5, prob=0.6),
            dict(type='Posterize', bits=5, prob=0.6)
        ],
        [
            dict(type='Equalize', prob=0.4),
            dict(type='Solarize', thr=256 / 9 * 5, prob=0.2)
        ],
        [
            dict(type='Equalize', prob=0.4),
            dict(type='Rotate', angle=30 / 9 * 8, prob=0.8)
        ],
        [
            dict(type='Solarize', thr=256 / 9 * 6, prob=0.6),
            dict(type='Equalize', prob=0.6)
        ],
        [dict(type='Posterize', bits=6, prob=0.8),
        dict(type='Equalize', prob=1.)],
        [
            dict(type='Rotate', angle=10., prob=0.2),
            dict(type='Solarize', thr=256 / 9, prob=0.6)
        ],
        [
            dict(type='Equalize', prob=0.6),
            dict(type='Posterize', bits=5, prob=0.4)
        ],
        [
            dict(type='Rotate', angle=30 / 9 * 8, prob=0.8),
            dict(type='ColorTransform', magnitude=0., prob=0.4)
        ],
        [
            dict(type='Rotate', angle=30., prob=0.4),
            dict(type='Equalize', prob=0.6)
        ],
        [dict(type='Equalize', prob=0.0),
        dict(type='Equalize', prob=0.8)],
        [dict(type='Invert', prob=0.6),
        dict(type='Equalize', prob=1.)],
        [
            dict(type='ColorTransform', magnitude=0.4, prob=0.6),
            dict(type='Contrast', magnitude=0.8, prob=1.)
        ],
        [
            dict(type='Rotate', angle=30 / 9 * 8, prob=0.8),
            dict(type='ColorTransform', magnitude=0.2, prob=1.)
        ],
        [
            dict(type='ColorTransform', magnitude=0.8, prob=0.8),
            dict(type='Solarize', thr=256 / 9 * 2, prob=0.8)
        ],
        [
            dict(type='Sharpness', magnitude=0.7, prob=0.4),
            dict(type='Invert', prob=0.6)
        ],
        [
            dict(
                type='Shear',
                magnitude=0.3 / 9 * 5,
                prob=0.6,
                direction='horizontal'),
            dict(type='Equalize', prob=1.)
        ],
        [
            dict(type='ColorTransform', magnitude=0., prob=0.4),
            dict(type='Equalize', prob=0.6)
        ],
        [
            dict(type='Equalize', prob=0.4),
            dict(type='Solarize', thr=256 / 9 * 5, prob=0.2)
        ],
        [
            dict(type='Solarize', thr=256 / 9 * 4, prob=0.6),
            dict(type='AutoContrast', prob=0.6)
        ],
        [dict(type='Invert', prob=0.6),
        dict(type='Equalize', prob=1.)],
        [
            dict(type='ColorTransform', magnitude=0.4, prob=0.6),
            dict(type='Contrast', magnitude=0.8, prob=1.)
        ],
        [dict(type='Equalize', prob=0.8),
        dict(type='Equalize', prob=0.6)],
    ]

    train_pipeline = [
        dict(type='LoadImageFromFile'),
        dict(type='RandomResizedCrop', size=224, backend='pillow'),
        dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
        dict(type='AutoAugment', policies=policies),
        dict(
            type='RandomErasing',
            erase_prob=0.2,
            mode='const',
            min_area_ratio=0.02,
            max_area_ratio=1 / 3,
            fill_color=img_norm_cfg['mean']),
        dict(type='Normalize', **img_norm_cfg),
        dict(type='ImageToTensor', keys=['img']),
        dict(type='ToTensor', keys=['gt_label']),
        dict(type='Collect', keys=['img', 'gt_label'])
    ]
    val_pipeline = [
        dict(type='LoadImageFromFile'),
        dict(type='Resize', size=(256, -1), backend='pillow'),
        dict(type='CenterCrop', crop_size=224),
        dict(type='Normalize', **img_norm_cfg),
        dict(type='ImageToTensor', keys=['img']),
        dict(type='Collect', keys=['img'])
    ]
    ```

- Train/Test

    ```python
    '''
    This part corresponds to the parameters required for training/testing;

    batch_size                 : Adjust according to your own equipment, it is recommended to be a multiple of `2`
    num_workers                : The number of threads for loading data in Dataloader can be adjusted according to your own equipment.
    pretrained_flag            : If using pre-trained weights, set to True
    pretrained_weights         : weight path
    freeze_flag                : If freezing a certain part of training, set to True
    freeze_layers              : Optional freezing options include backbone, neck, and head
    epoches                    : Maximum iteration cycle

    ckpt : Weights file required to evaluate the model
    Note that if the number of categories is less than 5, the default top5 accuracy is 100%.
    `No other parameters need to be changed`
    '''
    data_cfg = dict(
        batch_size = 32,
        num_workers = 4,
        train = dict(
            pretrained_flag = False,
            pretrained_weights = './datas/mobilenet_v3_small.pth',
            freeze_flag = False,
            freeze_layers = ('backbone',),
            epoches = 100,
        ),
        test=dict(
            ckpt = 'logs/20220202091725/Val_Epoch019-Loss0.215.pth',
            metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'confusion'],
            metric_options = dict(
                topk = (1,5),
                thrs = None,
                average_mode='none'
        ))
    )
    ```

- Optimizer

    ```python
    '''
    Optimizer during training, corresponding to torch.optim

    type: 'RMSprop' corresponds to torch.optim.RMSprop, which can be viewed at torch.optim
    PyTorch supports Adadelta, Adagrad, Adam, AdamW, SparseAdam, Adamax, ASGD, SGD, Rprop, RMSprop, Optimizer, LBFGS
    You can choose the optimizer according to your needs

    lr: initial learning rate, which can be adjusted according to your own Batch Size
    ckpt: weight file required to evaluate the model

    No other parameters need to be changed
    '''
    optimizer_cfg = dict(
        type='RMSprop',
        lr=0.001,
        alpha=0.9,
        momentum=0.9,
        eps=0.0316,
        weight_decay=1e-5)
    ```

- Learning Rate

    ```python
    '''
    Learning rate update strategy, each method can be viewed at src/core/optimizers/lr_update.py

    StepLrUpdater            : linear decrease
    CosineAnnealingLrUpdater : cosine annealing

    by_epoch                 : Whether to update the learning rate every Epoch
    warmup                   : Before officially using the learning rate update strategy, first use warmup small learning rate training, optional constant, linear, exp
    warmup_ratio             : Combined with `lr` in `Optimizer`, the selected warmup method is used to update the learning rate calculation.
    warmup_by_epoch          : The function is similar to `by_epoch`. If it is False, it will be updated for each step (Batch), otherwise every cycle
    warmup_iters             : Warmup action duration, warmup_by_epoch is True, which represents the period, and False, which represents the number of steps.
    '''
    lr_config = dict(
        type='CosineAnnealingLrUpdater',
        by_epoch=False,
        min_lr_ratio=1e-2,
        warmup='linear',
        warmup_ratio=1e-3,
        warmup_iters=20,
        warmup_by_epoch=True)
    ```
